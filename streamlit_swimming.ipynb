{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5055da2f-569c-4d02-be9f-6df7dea32fb0",
   "metadata": {},
   "source": [
    "### Instalaci√≥n de dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bef2809-bff9-47f0-98c1-1181496d7ca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T15:09:05.575695Z",
     "iopub.status.busy": "2026-01-20T15:09:05.574858Z",
     "iopub.status.idle": "2026-01-20T15:09:05.610078Z",
     "shell.execute_reply": "2026-01-20T15:09:05.608673Z",
     "shell.execute_reply.started": "2026-01-20T15:09:05.575630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Verificando librer√≠as...\n",
      "   ‚úÖ langchain ya instalado (v1.2.0)\n",
      "   ‚úÖ langchain-google-genai ya instalado (v4.1.1)\n",
      "   ‚úÖ langchain-community ya instalado (v0.4.1)\n",
      "   ‚úÖ langchain-core ya instalado (v1.2.7)\n",
      "   ‚úÖ langsmith ya instalado (v0.5.0)\n",
      "   ‚úÖ langgraph ya instalado (v1.0.5)\n",
      "   ‚úÖ streamlit ya instalado (v1.52.1)\n",
      "\n",
      "El entorno est√° configurado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "from importlib.util import find_spec\n",
    "from importlib.metadata import version, PackageNotFoundError\n",
    "\n",
    "PACKAGES_TO_INSTALL = [ \n",
    "                        'langchain==1.2.0',\n",
    "                        'langchain-google-genai==4.1.1',\n",
    "                        'langchain-community==0.4.1',\n",
    "                        'langchain-core==1.2.2',\n",
    "                        'langsmith==0.5.0',\n",
    "                        'langgraph==1.0.5',\n",
    "                        'streamlit==1.52.1'\n",
    "                      ]\n",
    "                       \n",
    "def manage_installation():\n",
    "    required_restart = False\n",
    "\n",
    "    # --- Configuraci√≥n del nivel de logs\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "    \n",
    "    print(\"üîç Verificando librer√≠as...\")\n",
    "    \n",
    "    for package in PACKAGES_TO_INSTALL:\n",
    "        pkg_name = package.split(\"==\")[0]\n",
    "        try:\n",
    "            v = version(pkg_name)\n",
    "            print(f\"   ‚úÖ {pkg_name} ya instalado (v{v})\")\n",
    "        except PackageNotFoundError:\n",
    "            print(f\"   ‚ö†Ô∏è {pkg_name} NO encontrado. Instalando...\")\n",
    "            subprocess.check_call([sys.executable, \n",
    "                                   \"-m\", \"pip\", \"install\", \n",
    "                                   \"--quiet\", \"--no-deps\", \"--disable-pip-version-check\", \"--no-warn-script-location\",\n",
    "                                   package])\n",
    "            required_restart = True\n",
    "            \n",
    "    if required_restart:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"üîÑ Librer√≠as instaladas. Reiniciando Kernel...\")\n",
    "        print(\"üõë Cuando el Kernel se reactive, ejecuta de nuevo esta casilla.\")\n",
    "        print(\"=\"*50)\n",
    "        time.sleep(4) \n",
    "        os._exit(00)\n",
    "    else:\n",
    "        print(\"\\nEl entorno est√° configurado correctamente.\")\n",
    "\n",
    "manage_installation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0c5451-d7cf-461a-87f4-cf2b84683963",
   "metadata": {},
   "source": [
    "### Activaci√≥n de las API necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46022d53-aa35-4c78-83cc-44c16434c11e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T15:09:05.612570Z",
     "iopub.status.busy": "2026-01-20T15:09:05.612055Z",
     "iopub.status.idle": "2026-01-20T15:09:09.134029Z",
     "shell.execute_reply": "2026-01-20T15:09:09.132790Z",
     "shell.execute_reply.started": "2026-01-20T15:09:05.612508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apikeys.googleapis.com                    API Keys API\n",
      "generativelanguage.googleapis.com         Generative Language API\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud services enable apikeys.googleapis.com\n",
    "gcloud services enable generativelanguage.googleapis.com\n",
    "gcloud services list --enabled | grep -e 'apikeys' -e 'generative'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8990325b-d1d1-46f6-ac5a-1061d9bde997",
   "metadata": {},
   "source": [
    "### Definici√≥n de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5436f434-0296-4288-8d75-51f9c6b3b866",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T15:09:09.135909Z",
     "iopub.status.busy": "2026-01-20T15:09:09.135553Z",
     "iopub.status.idle": "2026-01-20T15:09:12.927211Z",
     "shell.execute_reply": "2026-01-20T15:09:12.925504Z",
     "shell.execute_reply.started": "2026-01-20T15:09:09.135876Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID: qwiklabs-gcp-03-cd2e31c60bb7\n",
      "REGION: us-central1\n",
      "ZONE: us-central1-a\n",
      "INSTANCE_NAME: instance-20260120-150635\n",
      "INSTANCE_NAME_IP: 34.58.78.71\n",
      "MODEL_NAME: gemini-2.5-flash-lite\n"
     ]
    }
   ],
   "source": [
    "# --- Creaci√≥n y Asignaci√≥n de las variables\n",
    "PROJECT_ID = !gcloud config get-value project 2> /dev/null\n",
    "PROJECT_ID = PROJECT_ID[0].strip()\n",
    "\n",
    "REGION = \"us-central1\"\n",
    "ZONE = \"us-central1-a\"\n",
    "\n",
    "INSTANCE_NAME = !gcloud compute instances list \\\n",
    "                   --filter='tags.items:(\"notebook-instance\" \"deeplearning-vm\")' \\\n",
    "                   --format=\"value(name)\"\n",
    "INSTANCE_NAME = INSTANCE_NAME[0]\n",
    "\n",
    "INSTANCE_NAME_IP = !gcloud compute instances describe $INSTANCE_NAME --zone=$ZONE --format='get(networkInterfaces[0].accessConfigs[0].natIP)'\n",
    "INSTANCE_NAME_IP = INSTANCE_NAME_IP[0].strip()\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\" \n",
    "\n",
    "# --- Registro como variables de entorno\n",
    "os.environ[\"PROJECT_ID\"] = f\"{PROJECT_ID}\"\n",
    "os.environ[\"REGION\"] = REGION  \n",
    "os.environ[\"ZONE\"] = ZONE  \n",
    "os.environ[\"INSTANCE_NAME\"] = INSTANCE_NAME  \n",
    "os.environ[\"INSTANCE_NAME_IP\"] = INSTANCE_NAME_IP  \n",
    "os.environ[\"MODEL_NAME\"] = f\"{MODEL_NAME}\"\n",
    "\n",
    "# --- Visualizaci√≥n de las variables \n",
    "print(f\"PROJECT_ID: {PROJECT_ID}\")\n",
    "print(f\"REGION: {REGION}\")\n",
    "print(f\"ZONE: {ZONE}\")\n",
    "print(f\"INSTANCE_NAME: {INSTANCE_NAME}\")\n",
    "print(f\"INSTANCE_NAME_IP: {INSTANCE_NAME_IP}\")\n",
    "print(f\"MODEL_NAME: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799149cf-8c1b-4f8e-b4e0-4ded7620dda6",
   "metadata": {},
   "source": [
    "### Creaci√≥n de una regla de firewall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "676129a9-bf00-4c78-aaae-7b38eba0122e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T15:09:12.929527Z",
     "iopub.status.busy": "2026-01-20T15:09:12.929142Z",
     "iopub.status.idle": "2026-01-20T15:09:15.993786Z",
     "shell.execute_reply": "2026-01-20T15:09:15.992641Z",
     "shell.execute_reply.started": "2026-01-20T15:09:12.929479Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME             NETWORK  DIRECTION  PRIORITY  ALLOW     DENY  DISABLED\n",
      "allow-streamlit  default  INGRESS    1000      tcp:8501        False\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud compute firewall-rules create allow-streamlit \\\n",
    "    --direction=INGRESS \\\n",
    "    --priority=1000 \\\n",
    "    --network=default \\\n",
    "    --action=ALLOW \\\n",
    "    --rules=tcp:8501 \\\n",
    "    --source-ranges=0.0.0.0/0 2> /dev/null\n",
    "\n",
    "gcloud compute firewall-rules list --filter name='allow-streamlit' 2> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2650fa36-4da1-4141-abc9-3b226984bc79",
   "metadata": {},
   "source": [
    "### Creaci√≥n de la credencial API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce98790-479a-4d45-b85c-7d4e63e708c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T15:09:15.996035Z",
     "iopub.status.busy": "2026-01-20T15:09:15.995549Z",
     "iopub.status.idle": "2026-01-20T15:09:17.897211Z",
     "shell.execute_reply": "2026-01-20T15:09:17.896139Z",
     "shell.execute_reply.started": "2026-01-20T15:09:15.995980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API_KEY (api-key-gemini) ya existe\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "GOOGLE_API_KEY=\"\"\n",
    "API_KEY_NAME=\"api-key-gemini\"\n",
    "\n",
    "API_KEY_UID = !gcloud services api-keys list --filter=\"displayName=$API_KEY_NAME\" --format=\"value(name)\" --quiet 2> /dev/null\n",
    "if len(API_KEY_UID) == 0:\n",
    "    API_KEY = !gcloud services api-keys create --display-name=$API_KEY_NAME --format=\"value(response.keyString)\" --quiet 2> /dev/null\n",
    "    print(f\"API_KEY ({API_KEY_NAME}) creada\")  \n",
    "else:\n",
    "    print(f\"API_KEY ({API_KEY_NAME}) ya existe\")\n",
    "    API_KEY_UID = API_KEY_UID[0].strip()\n",
    "    API_KEY = !gcloud services api-keys get-key-string $API_KEY_UID | cut -d\" \" -f2\n",
    "API_KEY = API_KEY[0].strip()\n",
    "if API_KEY != \"\": \n",
    "    os.environ[\"GOOGLE_API_KEY\"] = API_KEY  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd41f71-a00e-470b-98da-8a70d0e3138d",
   "metadata": {},
   "source": [
    "### Construcci√≥n de la aplicaci√≥n Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0db81d6-38a2-47ca-a04d-a08a4df8b62e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T15:12:31.217428Z",
     "iopub.status.busy": "2026-01-20T15:12:31.216432Z",
     "iopub.status.idle": "2026-01-20T15:12:31.231747Z",
     "shell.execute_reply": "2026-01-20T15:12:31.230136Z",
     "shell.execute_reply.started": "2026-01-20T15:12:31.217271Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting streamlit_swimming.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile streamlit_swimming.py\n",
    "import streamlit as st\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "\n",
    "# ----------------------------------\n",
    "#  Configuraci√≥n\n",
    "# ----------------------------------\n",
    "\n",
    "# --- Configuraci√≥n de la p√°gina\n",
    "st.set_page_config(page_title=\"Coach Nataci√≥n AI\", page_icon=\"üèä\", layout=\"centered\")\n",
    "\n",
    "# --- Configuraci√≥n del nivel de logs\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# --- Lectura de la API Key\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not GOOGLE_API_KEY:\n",
    "    st.error(\"‚ùå Error: Falta la API Key\")\n",
    "    st.stop()\n",
    "\n",
    "# --- Configuraci√≥n de variables de entorno\n",
    "PROJECT_ID = os.environ.get(\"PROJECT_ID\")\n",
    "MODEL_NAME = os.environ.get(\"MODEL_NAME\")\n",
    "\n",
    "# ----------------------------------\n",
    "#  Definici√≥n de Funciones (tool)\n",
    "# ----------------------------------\n",
    "\n",
    "# --- Funci√≥n Python que simula buscar en un PDF\n",
    "@tool\n",
    "def consultar_minimas_rfen(piscina: str = \"50m\"):\n",
    "    \"\"\"\n",
    "    √öSALA SIEMPRE que pregunten por tiempos m√≠nimos, marcas m√≠nimas, m√≠nimas nacionales\n",
    "    o requisitos de clasificaci√≥n para campeonatos de Espa√±a.\n",
    "    \n",
    "    Args:\n",
    "        piscina: El tama√±o de la piscina, por defecto '50m' (larga) o '25m' (corta).\n",
    "    \n",
    "    Devuelve un JSON simulando la extracci√≥n de datos de un PDF oficial de la RFEN.\n",
    "    \"\"\"\n",
    "    time.sleep(2) # Simulamos el tiempo de lectura/procesamiento del PDF\n",
    "\n",
    "    # Datos simulados (mock) que devolver√≠a el lector de PDF\n",
    "    datos_simulados = {\n",
    "        \"fuente\": \"Normativa_RFEN_2024_2025.pdf\",\n",
    "        \"piscina\": piscina,\n",
    "        \"tiempos_minimos\": {\n",
    "            \"50 Libres\": \"25.10 (M) / 28.50 (F)\",\n",
    "            \"100 Libres\": \"54.80 (M) / 1:01.20 (F)\",\n",
    "            \"100 Mariposa\": \"59.90 (M) / 1:06.50 (F)\",\n",
    "            \"200 Estilos\": \"2:15.50 (M) / 2:28.00 (F)\"\n",
    "        },\n",
    "        \"nota\": \"Marcas v√°lidas para el Campeonato de Espa√±a de Verano\"\n",
    "    }\n",
    "    return datos_simulados\n",
    "\n",
    "tools = [consultar_minimas_rfen]\n",
    "\n",
    "# ----------------------------------\n",
    "# Configuraci√≥n e Inicializaci√≥n\n",
    "# ----------------------------------\n",
    "\n",
    "# --- System Instructions (Contexto de Nataci√≥n)\n",
    "prompt_template = \"\"\"\n",
    "    Eres un Asistente Experto en Nataci√≥n Competitiva y entrenador de alto rendimiento.\n",
    "\n",
    "    - Si te preguntan por tiempos, m√≠nimas, marcas de clasificaci√≥n o datos oficiales de la RFEN, DEBES usar la herramienta `consultar_minimas_rfen`.\n",
    "    - NO inventes tiempos m√≠nimos. Si la herramienta no devuelve el dato exacto, di que son datos aproximados basados en la normativa vigente.\n",
    "    - Tras usar la herramienta, responde SIEMPRE con este formato claro:\n",
    "      \n",
    "      üìã **M√çNIMAS NACIONALES**: \n",
    "      - Prueba: [Nombre prueba] -> [Tiempo Masculino] / [Tiempo Femenino]\n",
    "      *(A√±ade tantos como hayas recuperado)*\n",
    "      ‚ö†Ô∏è *Fuente: Normativa RFEN.*\n",
    "\n",
    "    - Si realizan preguntas t√©cnicas sobre nataci√≥n (t√©cnica de viraje, c√≥mo mejorar la patada de braza, frecuencia de brazada, zonas de entrenamiento...), responde usando tu conocimiento general como entrenador experto.\n",
    "    - Si la pregunta NO est√° relacionada con la nataci√≥n o el deporte (ej: pol√≠tica, cocina), responde: 'Solo estoy programado para responder sobre nataci√≥n competitiva'.\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------\n",
    "#  Configuraci√≥n del Agente\n",
    "# ----------------------------------\n",
    "@st.cache_resource\n",
    "def iniciar_agente():\n",
    "    try:\n",
    "        llm = ChatGoogleGenerativeAI(\n",
    "            model=MODEL_NAME,\n",
    "            google_api_key=GOOGLE_API_KEY,\n",
    "            temperature=0,\n",
    "            convert_system_message_to_human=True \n",
    "        )\n",
    "        return create_react_agent(llm, tools=tools)\n",
    "    except Exception as e:\n",
    "        # Si falla, no podemos hacer mucho m√°s que mostrar error\n",
    "        return None\n",
    "     \n",
    "estado = f\"üèä Conectado a {PROJECT_ID} ({MODEL_NAME}) - Coach AI\"     \n",
    "agent = iniciar_agente()\n",
    "\n",
    "# ----------------------------------\n",
    "# Dise√±o de la interfaz de usuario\n",
    "# ----------------------------------\n",
    "st.title(\"üèä Chatbot de Nataci√≥n RFEN\")\n",
    "st.caption(estado)\n",
    "\n",
    "if not agent:\n",
    "    st.error(\"Error al iniciar el agente. Verifica tus variables de entorno.\")\n",
    "    st.stop()\n",
    "\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Renderizar historial previo\n",
    "for msg in st.session_state.messages:\n",
    "    if isinstance(msg, (HumanMessage, AIMessage)):\n",
    "        role = \"user\" if isinstance(msg, HumanMessage) else \"assistant\"\n",
    "        with st.chat_message(role):\n",
    "            st.markdown(msg.content)\n",
    "\n",
    "# -- Input de Usuario\n",
    "if prompt := st.chat_input(\"Ej: ¬øCu√°l es la m√≠nima de 100 libres Infantil?\"):\n",
    "   \n",
    "  # -- Escritura del mensaje de usuario\n",
    "  st.session_state.messages.append(HumanMessage(content=prompt))\n",
    "  with st.chat_message(\"user\"):\n",
    "    st.markdown(prompt)\n",
    "\n",
    "  # -- L√≥gica del Agente (Asistente)\n",
    "  with st.chat_message(\"assistant\"):\n",
    "     \n",
    "    # -- Variables para guardar el resultado y usarlo fuera\n",
    "    response = None\n",
    "    texto_final = \"\"\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Visualizaci√≥n (Bloque de Pensamiento)\n",
    "    # ---------------------------------------------------------\n",
    "    with st.status(\"‚è±Ô∏è Analizando tiempos y t√©cnica...\", expanded=True) as status:\n",
    "      try:\n",
    "        # -- Preparaci√≥n del input (prompt de entrada)\n",
    "        sys_msg = SystemMessage(content=prompt_template)\n",
    "        mensajes_input = [sys_msg] + st.session_state.messages\n",
    "         \n",
    "        # -- Ejecuci√≥n del Agente\n",
    "        response = agent.invoke({\"messages\": mensajes_input})\n",
    "         \n",
    "        # -- Visualizaci√≥n de pasos intermedios\n",
    "        mensajes_totales = response[\"messages\"]\n",
    "        nuevos_mensajes = mensajes_totales[len(mensajes_input):]\n",
    "        herramienta_usada = False\n",
    "\n",
    "        for msg in nuevos_mensajes:\n",
    "          if isinstance(msg, AIMessage) and msg.tool_calls:\n",
    "            for call in msg.tool_calls:\n",
    "              st.write(f\"üìÑ **Acci√≥n:** Buscando en PDF normativa para `{call['args']}`\")\n",
    "              herramienta_usada = True\n",
    "          elif isinstance(msg, ToolMessage):\n",
    "            st.write(\"üíæ **Datos extra√≠dos del PDF:**\")\n",
    "            st.code(msg.content, language=\"json\")\n",
    "\n",
    "        # Cierre de la caja de An√°lisis (Pensamiento)\n",
    "        if herramienta_usada:\n",
    "          status.update(label=\"‚úÖ Normativa localizada\", state=\"complete\", expanded=False)\n",
    "        else:\n",
    "          status.update(label=\"‚ÑπÔ∏è Respuesta t√©cnica (sin b√∫squeda)\", state=\"complete\", expanded=False)\n",
    "\n",
    "      except Exception as e:\n",
    "        status.update(label=\"‚ùå Error\", state=\"error\")\n",
    "        st.error(f\"Error: {e}\")\n",
    "        st.stop()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    #  Respuesta Final\n",
    "    # ---------------------------------------------------------\n",
    "    if response:\n",
    "      ultimo_mensaje = response[\"messages\"][-1]\n",
    "      raw_content = ultimo_mensaje.content\n",
    "       \n",
    "      # --- Limpieza b√°sica\n",
    "      if isinstance(raw_content, list):\n",
    "         texto_final = \"\".join([x.get(\"text\", \"\") for x in raw_content if isinstance(x, dict)])\n",
    "      else:\n",
    "         texto_final = str(raw_content)\n",
    "       \n",
    "      # -- Impresi√≥n en el Chat Principal\n",
    "      st.markdown(texto_final)\n",
    "       \n",
    "      # -- Almacenamiento en el historial\n",
    "      st.session_state.messages.append(AIMessage(content=texto_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9780ad0f-ddc4-42ec-a98e-0862e7c0553e",
   "metadata": {},
   "source": [
    "### Reinicio de Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f36f382e-3fd0-4966-9c73-1c52f24c7f1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T15:13:16.784107Z",
     "iopub.status.busy": "2026-01-20T15:13:16.782892Z",
     "iopub.status.idle": "2026-01-20T15:13:18.926252Z",
     "shell.execute_reply": "2026-01-20T15:13:18.924710Z",
     "shell.execute_reply.started": "2026-01-20T15:13:16.784044Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Reiniciando Streamlit con gemini-2.5-flash-lite\n",
      "\n",
      "$ streamlit run streamlit_swimming.py --server.port 8501 > streamlit.log 2>&1 &\n",
      "\n",
      "‚úÖ Listo. Streamlit ejecut√°ndose en segundo plano con PID 14683\n"
     ]
    }
   ],
   "source": [
    "!pkill -f streamlit\n",
    "\n",
    "import time, subprocess\n",
    "\n",
    "time.sleep(2) \n",
    "print(f\"üîÑ Reiniciando Streamlit con {MODEL_NAME}\")\n",
    "print(\"\\n$ streamlit run streamlit_swimming.py --server.port 8501 > streamlit.log 2>&1 &\\n\")\n",
    "\n",
    "entorno = os.environ.copy()\n",
    "\n",
    "p = subprocess.Popen(\n",
    "    [\"streamlit\", \"run\", \"streamlit_swimming.py\", \"--server.port\", \"8501\"],\n",
    "    env=entorno,\n",
    "    stdout=open(\"streamlit_swimming.log\", \"w\"),\n",
    "    stderr=subprocess.STDOUT\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Listo. Streamlit ejecut√°ndose en segundo plano con PID {p.pid}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813481d0-2b51-42f9-9fb9-e46ae1dec344",
   "metadata": {},
   "source": [
    "### URL de la aplicaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03565617-34e2-4d2d-a27e-59708b8fc934",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2026-01-20T15:09:20.064737Z",
     "iopub.status.busy": "2026-01-20T15:09:20.064170Z",
     "iopub.status.idle": "2026-01-20T15:09:25.087119Z",
     "shell.execute_reply": "2026-01-20T15:09:25.085598Z",
     "shell.execute_reply.started": "2026-01-20T15:09:20.064675Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\n",
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8501\n",
      "  Network URL: http://10.128.0.2:8501\n",
      "  External URL: http://34.58.78.71:8501\n",
      "\n",
      "  Stopping...\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "sleep 5\n",
    "cat streamlit_langchain.log"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m138",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m138"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
